# Local AI Chatbot (Ollama)

This repository contains multiple chatbot implementations using **local Large Language Models (LLM)** powered by **Ollama**.

The goal of this project is to demonstrate:
- Local AI inference (offline, no API key)
- Streamlit UI development
- Backend architecture using FastAPI
- Clean separation between frontend and backend

---

## ğŸ“ Projects Included

### 1. Streamlit â†’ Ollama
A simple chatbot where Streamlit directly communicates with Ollama.

### 2. Streamlit â†’ FastAPI â†’ Ollama
A more scalable architecture where:
- Streamlit handles UI only
- FastAPI handles AI requests
- Ollama runs as the local inference engine

---

## ğŸ›  Tech Stack
- Python
- Streamlit
- FastAPI
- Ollama
- Gemma model

---

## ğŸ’¡ Why Local AI?
- No API key required
- Full data privacy
- Better understanding of AI system architecture
- Resource-aware development (RAM & CPU constraints)

---
